# -*- coding: utf-8 -*-
"""Semantic_text_Similarity.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/Mwadz/Sematic-Text-Similarity/blob/main/Semantic_text_Similarity.ipynb
"""

#! pip install datasets
#! pip install sentence_transformers

#loading training set
import pandas as pd
import numpy as np
from tqdm import tqdm
tqdm.pandas()
from datasets import load_dataset


# Load the English STSB dataset
stsb_dataset = load_dataset('stsb_multi_mt', 'en')
stsb_train = pd.DataFrame(stsb_dataset['train'])
stsb_test = pd.DataFrame(stsb_dataset['test'])

# Check loaded data
print(stsb_train.shape, stsb_test.shape)
stsb_test.head()

"""## Creating helper functions
* The first function is to pre-process texts by lemmatizing, lowercasing, and removing numbers and stop words.
* The second function takes in two columns of text embeddings and returns the row-wise cosine similarity between the two columns.
"""

from sklearn.metrics.pairwise import cosine_similarity
import spacy
nlp = spacy.load("en_core_web_sm")

def text_processing(sentence):
    """
    Lemmatize, lowercase, remove numbers and stop words

    Args:
      sentence: The sentence we want to process.

    Returns:
      A list of processed words
    """
    sentence = [token.lemma_.lower()
                for token in nlp(sentence)
                if token.is_alpha and not token.is_stop]

    return sentence


def cos_sim(sentence1_emb, sentence2_emb):
    """
    Cosine similarity between two columns of sentence embeddings

    Args:
      sentence1_emb: sentence1 embedding column
      sentence2_emb: sentence2 embedding column

    Returns:
      The row-wise cosine similarity between the two columns.
      For instance is sentence1_emb=[a,b,c] and sentence2_emb=[x,y,z]
      Then the result is [cosine_similarity(a,x), cosine_similarity(b,y), cosine_similarity(c,z)]
    """
    cos_sim = cosine_similarity(sentence1_emb, sentence2_emb)
    return np.diag(cos_sim)

data = (pd.read_csv("/content/SBERT_data.csv")).drop(['Unnamed: 0'], axis = 1)

prompt = input("Enter prompt: ")
data['prompt']= prompt
data.rename(columns = {'target_text':'sentence2', 'prompt':'sentence1'}, inplace = True)
data['sentence2'] = data['sentence2'].astype('str')
data['sentence1']  = data['sentence1'].astype('str')

data.head()

from sentence_transformers import CrossEncoder
XpathFinder = CrossEncoder("cross-encoder/stsb-roberta-base")
sentence_pairs = []
for sentence1, sentence2 in zip(data['sentence1'],data['sentence2']):
  sentence_pairs.append([sentence1, sentence2])

data['SBERT CrossEncoder_Score'] = XpathFinder.predict(sentence_pairs, show_progress_bar = True)

data.sort_values(by=['SBERT CrossEncoder_Score'], ascending=False)

import pickle

filename = 'XpathFinder1.sav'
pickle.dump(XpathFinder, open(filename, 'wb'))

#!pip install -q streamlit

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
import io
import netrc
import pickle
import sys
import pandas as pd
import streamlit as st
#  let's import sentence transformer
# import sentence_transformers
import torch
# #######################################

st.markdown(
 f"""
<style>
 .reportview-container .main .block-container{{
     max-width: 90%;
     padding-top: 5rem;
     padding-right: 5rem;
     padding-left: 5rem;
     padding-bottom: 5rem;
 }}
 img{{
 	max-width:40%;
 	margin-bottom:40px;
 }}
</style>
""",
 unsafe_allow_html=True,
)

# # # let's load the saved model
loaded_model = pickle.load(open('XpathFinder1.sav', 'rb'))
# #loaded_model = pickle.load('XpathFinder1.sav', map_location='cpu')
#
#
# #class CPU_Unpickler(pickle.Unpickler):
# #    def find_class(self, module, name):
# #        if module == 'torch.storage' and name == '_load_from_bytes':
# #            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')
# #        else:
# #            return super().find_class(module, name)
# #
#
# #loaded_model = CPU_Unpickler(open('XpathFinder1.sav', 'rb')).load()
#
#
# # here is how to create containers
header_container = st.container()
stats_container = st.container()

#the header
with header_container:

    # different levels of text you can include in your app
    st.title("Semantic Text Similarity App")
    st.header("Hello!, Let's match some words!!!")
#
# # Another container
with stats_container:
    # collect input using free text
    text_input = st.text_input("Enter the text in the space below ...")

    # let's pass the input to the loaded_model with torch compiled with cuda
    if text_input:
        # let's get the result
        result = loaded_model.predict([text_input])
        # let's show the result
        st.write(result)

#!pip install pyngrok

from pyngrok import ngrok

ngrok.set_auth_token("2EolZMbfSIIvEtovVRdA5Gi7KJY_3AKjE4jHU5udEjXfT6noE")

nohup streamlit run app.py --server.port 80 &
url = ngrok.connect(port = '80')
print(url)
